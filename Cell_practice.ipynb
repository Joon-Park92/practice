{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cell(object):\n",
    "    def __init__(self):        \n",
    "        self.layer_size = 10\n",
    "        self.input_hidden = 15\n",
    "    \n",
    "    def __call__(self, inputs, states):\n",
    "        with tf.variable_scope('cell', reuse=tf.AUTO_REUSE):            \n",
    "            stack = tf.concat([inputs, states],axis = -1)\n",
    "            out = tf.layers.dense(stack, self.layer_size)\n",
    "        return out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell_ = cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_rnn(cell):\n",
    "    \n",
    "    def cond(i, inputs, *args):\n",
    "        return tf.less(i, inputs.shape[1])\n",
    "\n",
    "    def body(i, input_, state_, outputs):        \n",
    "        input__ = tf.gather(input_, i, axis = 1)\n",
    "        out, states = cell_(input__, state_)\n",
    "        outputs = outputs.write(i, out)\n",
    "        i = tf.add(i, 1)    \n",
    "        return i, input_, states, outputs\n",
    "    \n",
    "    outputs = tf.TensorArray(dtype=tf.float32, size=inputs.shape[1])\n",
    "\n",
    "    _, _, state, outputs = tf.while_loop(cond, body, [tf.constant(0), inputs, initial_state, outputs])\n",
    "    \n",
    "    return outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layer_size= 10\n",
    "input_hidden = 15\n",
    "\n",
    "inputs = tf.constant(4, shape=[2,3,layer_size], dtype=tf.float32)\n",
    "initial_state = tf.constant(0, shape=[2,layer_size], dtype=tf.float32)\n",
    "\n",
    "def cond(i, inputs, *args):\n",
    "    return tf.less(i, inputs.shape[1])\n",
    "\n",
    "def body(i, input_, state_, outputs):        \n",
    "    input__ = tf.gather(input_, i, axis = 1)\n",
    "    out, states = cell_(input__, state_)\n",
    "    outputs = outputs.write(i, out)\n",
    "    i = tf.add(i, 1)    \n",
    "    return i, input_, states, outputs\n",
    "\n",
    "outputs = tf.TensorArray(dtype=tf.float32, size=inputs.shape[1])\n",
    "\n",
    "_, _, state, outputs = tf.while_loop(cond, body, [tf.constant(0), inputs, initial_state, outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(tf.transpose(outputs.stack(),[1,0,2])).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell oject 를 스스로 만드는 것보다 tensorflow의 cell object를 상속받아서 cell을 수정하는 것이 많은 Wrapper를 사용할 수 있기 때문에 효율적일 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StateTuple = namedtuple('StateTuple', ['cell_state', 'hidden_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMCell(object):\n",
    "    \"\"\"Basic LSTM cell \n",
    "    \n",
    "    Args:\n",
    "        num_unit : layer size of LSTMcell\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_unit, scope):\n",
    "        self._state_size = num_unit\n",
    "        self._output_size = num_unit\n",
    "        self._scope = scope\n",
    "        \n",
    "    def __call__(self, input_, state_tuple):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ : 2-D tensor, [Batch_size, Input_embedding_size]\n",
    "            state_tuple : namedtuple, which has two properties ['cell_state', 'hidden_state']\n",
    "                cell_state   : 2-D tensor, [Batch_size, state_size]\n",
    "                hidden_state : 2-D tensor, [Batch_size, state_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        cell_state = state_tuple.cell_state\n",
    "        hidden_state = state_tuple.hidden_state\n",
    "        \n",
    "        concat = tf.concat([input_, hidden_state], axis = -1)\n",
    "        concat_size = tf.shape(concat)[-1]\n",
    "        \n",
    "        sigmoid = tf.sigmoid\n",
    "        tanh = tf.tanh\n",
    "        \n",
    "        with tf.variable_scope(self._scope, reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            kernel = tf.layers.dense(concat,\n",
    "                                     units=self.state_size * 4,\n",
    "                                     activation=None,\n",
    "                                     kernel_initializer=tf.truncated_normal_initializer(stddev=self.state_size**(-1/2)),\n",
    "                                     bias_initializer= tf.constant_initializer(),\n",
    "                                     name='kernel')\n",
    "            \n",
    "            f, i, C, o = tf.split(kernel, 4, axis=-1)          \n",
    "                                \n",
    "            after_forget = tf.multiply(cell_state, sigmoid(f))\n",
    "            next_cell_state = tf.add(after_forget, tf.multiply(sigmoid(i), tanh(C)))\n",
    "            next_hidden_state = tf.multiply(tanh(next_cell_state), sigmoid(o))\n",
    "            \n",
    "            output = next_hidden_state\n",
    "            next_state_tuple = StateTuple(next_cell_state, next_hidden_state)\n",
    "            \n",
    "            \n",
    "        return output, next_state_tuple\n",
    "    \n",
    "    def get_initial_state(self, batch_size, dtype=None):\n",
    "        \n",
    "        cell_state = tf.constant(0, dtype=dtype, shape=[batch_size, self._state_size])\n",
    "        hidden_state = tf.constant(0, dtype=dtype, shape=[batch_size, self._state_size])\n",
    "        Tuple = StateTuple(cell_state, hidden_state)        \n",
    "        \n",
    "        return Tuple\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._state_size  \n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_rnn(cell, input_):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        cell: cell object \n",
    "        inputs_: 3-D tensor that has shape of [Batch, Time, Embedding_size]\n",
    "    \n",
    "    Returns:\n",
    "        outputs: 3-D tensor that has shape of [Batch, Time, Layer_hidden_size]\n",
    "        last_state: List of StateTuple, Last hidden state of Cell\n",
    "    \"\"\"\n",
    "    \n",
    "    time_step = input_.shape[1]\n",
    "    i = tf.constant(0, dtype=tf.int32)\n",
    "    \n",
    "    _output_tensor_array = tf.TensorArray(dtype=input_.dtype, \n",
    "                                          size=time_step, \n",
    "                                          clear_after_read=False)\n",
    "    \n",
    "    \n",
    "    _cond = lambda i, *args : tf.less(i, time_step)    \n",
    "    \n",
    "    def _body(i, input_, state_tuple, _output_tensor_array):\n",
    "        \n",
    "        out, next_state = cell(input_[:,i,:], state_tuple)\n",
    "        _output_tensor_array = _output_tensor_array.write(i, out)\n",
    "        i = i + 1\n",
    "        \n",
    "        return i, input_, next_state, _output_tensor_array\n",
    "    \n",
    "    initial_vars = [i, input_, cell.get_initial_state(input_.shape[0], input_.dtype), _output_tensor_array]\n",
    "    \n",
    "    _, _, last_state, _outputs = tf.while_loop(_cond, _body, initial_vars)\n",
    "    \n",
    "    outputs = tf.transpose(_outputs.stack(), [1,0,2])\n",
    "    _outputs.close()\n",
    "    \n",
    "    return outputs, last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell = LSTMCell(256,'LSTM_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs, last_state = build_rnn(cell, tf.constant(1.0, dtype=tf.float32, shape=[10,12,15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiCell(object):\n",
    "    def __init__(self, cells):\n",
    "        self._state_size = sum([cell.state_size for cell in cells])\n",
    "        \n",
    "    def __call__(self, prev_input, prev_state):\n",
    "        \n",
    "        # for next state\n",
    "        tmp_state = []\n",
    "        \n",
    "        prev_outputs = prev_input\n",
    "        prev_states = prev_state.unstack(-1)\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            cur_output, cur_state = cell(prev_output, states)\n",
    "            tmp_state.append(cur_state)\n",
    "            prev_output = cur_output                        \n",
    "    \n",
    "    def get_initial_state():\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._state_size\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._output_size"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
